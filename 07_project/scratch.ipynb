{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch pad\n",
    "\n",
    "Use this notebook for quick & dirty tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset loading\n",
    "'''\n",
    "original_columns = ['has_null', 'wave', 'gender', 'age', 'age_o', 'd_age', 'd_d_age', 'race', 'race_o', 'samerace', 'importance_same_race', 'importance_same_religion', 'd_importance_same_race', 'd_importance_same_religion', 'field', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important', 'd_attractive_important', 'd_sincere_important', 'd_intellicence_important', 'd_funny_important', 'd_ambtition_important', 'd_shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'd_attractive', 'd_sincere', 'd_intelligence', 'd_funny', 'd_ambition', 'attractive_partner', 'sincere_partner', 'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner', 'd_attractive_partner', 'd_sincere_partner', 'd_intelligence_partner', 'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'd_sports', 'd_tvsports', 'd_exercise', 'd_dining', 'd_museums', 'd_art', 'd_hiking', 'd_gaming', 'd_clubbing', 'd_reading', 'd_tv', 'd_theater', 'd_movies', 'd_concerts', 'd_music', 'd_shopping', 'd_yoga', 'interests_correlate', 'd_interests_correlate', 'expected_happy_with_sd_people', 'expected_num_interested_in_me', 'expected_num_matches', 'd_expected_happy_with_sd_people', 'd_expected_num_interested_in_me', 'd_expected_num_matches', 'like', 'guess_prob_liked', 'd_like', 'd_guess_prob_liked', 'met', 'decision', 'decision_o', 'match']\n",
    "columns_no_intervals = ['has_null', 'wave', 'gender', 'age', 'age_o', 'd_age', 'race', 'race_o', 'samerace', 'importance_same_race', 'importance_same_religion', 'field', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'attractive_partner', 'sincere_partner', 'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'interests_correlate', 'expected_happy_with_sd_people', 'expected_num_interested_in_me', 'expected_num_matches', 'like', 'guess_prob_liked', 'met', 'match']\n",
    "\n",
    "# Making a list of missing value types\n",
    "missing_values = [\"n/a\", \"na\", \"--\", \"?\"]\n",
    "\n",
    "df = pd.read_csv('speeddating.csv', na_values=missing_values, usecols=columns_no_intervals)\n",
    "\n",
    "'''\n",
    "Data cleaning\n",
    "'''\n",
    "categorical = ['gender', 'race', 'race_o', 'field']\n",
    "numerical = ['has_null', 'wave', 'age', 'age_o', 'd_age', 'samerace', 'importance_same_race', 'importance_same_religion', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'attractive_partner', 'sincere_partner', 'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'interests_correlate', 'expected_happy_with_sd_people', 'expected_num_interested_in_me', 'expected_num_matches', 'like', 'guess_prob_liked', 'met']\n",
    "\n",
    "df['field'] = df['field'].str.lower()\n",
    "df['field'] = df['field'].str.replace(\"'\", \"\", regex=False)\n",
    "df['field'] = df['field'].str.replace(\" \", \"_\", regex=False)\n",
    "df['field'] = df['field'].str.replace(\"[\", \"(\", regex=False)\n",
    "df['field'] = df['field'].str.replace(\"]\", \")\", regex=False)\n",
    "df['field'] = df['field'].fillna('unknown')\n",
    "df['field'] = df['field'].astype(str)\n",
    "\n",
    "df['field'] = df['field'].str.replace('business-_mba', 'business_(mba)', regex=False)\n",
    "df['field'] = df['field'].str.replace('business/law', 'business_(law)', regex=False)\n",
    "df['field'] = df['field'].str.replace('business;_marketing', 'business_(marketing)', regex=False)\n",
    "df['field'] = df['field'].str.replace('business;_media', 'business_(media)', regex=False)\n",
    "df['field'] = df['field'].str.replace('business/_finance/_real_estate', 'business_(finance_&_real_estate)', regex=False)\n",
    "df['field'] = df['field'].str.replace('creative_writing_-_nonfiction', 'creative_writing_(nonfiction)', regex=False)\n",
    "df['field'] = df['field'].str.replace('climate-earth_and_environ._science', 'earth_and_environmental_science', regex=False)\n",
    "df['field'] = df['field'].str.replace('electrical_engg.', 'electrical_engineering', regex=False)\n",
    "df['field'] = df['field'].str.replace('finanace', 'finance', regex=False)\n",
    "df['field'] = df['field'].str.replace('finance&economics', 'finance_&_economics', regex=False)\n",
    "df['field'] = df['field'].str.replace('finance/economics', 'finance_&_economics', regex=False)\n",
    "df['field'] = df['field'].str.replace('international_affairs/business', 'international_affairs_(business)', regex=False)\n",
    "df['field'] = df['field'].str.replace('international_affairs/finance', 'international_affairs_(finance)', regex=False)\n",
    "df['field'] = df['field'].str.replace('international_affairs/international_finance', 'international_affairs_(finance)', regex=False)\n",
    "df['field'] = df['field'].str.replace('intrernational_affairs', 'international_affairs', regex=False)\n",
    "df['field'] = df['field'].str.replace('master_in_public_administration', 'masters_in_public_administration', regex=False)\n",
    "df['field'] = df['field'].str.replace('master_of_international_affairs', 'masters_in_international_affairs', regex=False)\n",
    "df['field'] = df['field'].str.replace('math', 'mathematics', regex=False)\n",
    "df['field'] = df['field'].str.replace('mfa__poetry', 'mfa_poetry', regex=False)\n",
    "df['field'] = df['field'].str.replace('mfa_-film', 'mfa_film', regex=False)\n",
    "#df['field'] = df['field'].str.replace('nan', 'unknown', regex=False)\n",
    "df['field'] = df['field'].str.replace('nutritiron', 'nutrition', regex=False)\n",
    "df['field'] = df['field'].str.replace('sipa_/_mia', 'masters_in_international_affairs', regex=False)\n",
    "df['field'] = df['field'].str.replace('sipa-international_affairs', 'international_affairs', regex=False)\n",
    "df['field'] = df['field'].str.replace('sociomedical_sciences-_school_of_public_health', 'sociomedical_sciences', regex=False)\n",
    "df['field'] = df['field'].str.replace('speech_languahe_pathology', 'speech_pathology', regex=False)\n",
    "df['field'] = df['field'].str.replace('speech_language_pathology', 'speech_pathology', regex=False)\n",
    "df['field'] = df['field'].str.replace('stats', 'statistics', regex=False)\n",
    "df['field'] = df['field'].str.replace('tc_(health_ed)', 'health_education', regex=False)\n",
    "\n",
    "df['race'] = df['race'].str.lower()\n",
    "df['race'] = df['race'].str.replace(\"'\", \"\", regex=False)\n",
    "df['race'] = df['race'].str.replace(\" \", \"_\", regex=False)\n",
    "\n",
    "df['race_o'] = df['race_o'].str.lower()\n",
    "df['race_o'] = df['race_o'].str.replace(\"'\", \"\", regex=False)\n",
    "df['race_o'] = df['race_o'].str.replace(\" \", \"_\", regex=False)\n",
    "\n",
    "df.race = df.race.fillna('Unknown')\n",
    "df.race_o = df.race_o.fillna('Unknown')\n",
    "\n",
    "for n in numerical:\n",
    "    df[n] = df[n].fillna(df[n].mean())\n",
    "\n",
    "'''\n",
    "Validation framework & one-hot encoding\n",
    "'''\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train.match.values\n",
    "y_test = df_test.match.values\n",
    "\n",
    "del df_full_train['match']\n",
    "del df_test['match']\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "full_train_dict = df_full_train.to_dict(orient='records')\n",
    "test_dict = df_test.to_dict(orient='records')\n",
    "\n",
    "X_full_train = dv.fit_transform(full_train_dict)\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "features = dv.get_feature_names()\n",
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train, feature_names=features)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test connection with `predict.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load a single user from the test dataset.\n",
    "'''\n",
    "X_single = X_test[0]\n",
    "X_single = np.expand_dims(X_single, axis=0)\n",
    "X_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the IP address here for sending the request.\n",
    "If the default 0.0.0.0 does not work, you can get the correct IP address from the output of:\n",
    "python predict.py\n",
    "'''\n",
    "url = 'http://0.0.0.0:9696/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change the number to any between 0 and 1000\n",
    "'''\n",
    "user = df_test.loc[30].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(url, json=user).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud deployment test\n",
    "\n",
    "Use this code if you have a running instance on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'match-env-public.eba-itm7djd5.eu-west-3.elasticbeanstalk.com'\n",
    "url = f'http://{host}/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change the number to any between 0 and 1000\n",
    "'''\n",
    "user = df_test.loc[30].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(url, json=user).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_path = 'dv.bin'\n",
    "model_path = 'model.bin'\n",
    "\n",
    "with open(dv_path, 'rb') as f_in:\n",
    "    dv = pickle.load(f_in)\n",
    "\n",
    "with open(model_path, 'rb') as f_in:\n",
    "    model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a match locally with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsingle = xgb.DMatrix(X_single, feature_names=dv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dsingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2793f5ae2d759d5672dd13ca141571e899773377b8bc8e5b8bbacc270ef885cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml-zoomcamp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
