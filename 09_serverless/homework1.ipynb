{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 9 homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we'll deploy the dogs vs cats model we trained in the previous homework.\n",
    "\n",
    "Download the model from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats-model/dogs_cats_10_0.687.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the converted model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 00:11:24.900138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('dogs_cats_10_0.687.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 00:11:26.735476: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z6/wchwkzy93yqb85l4qc39505r0000gn/T/tmpl_cmpudl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 00:11:27.463179: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-11-26 00:11:27.463257: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-11-26 00:11:27.464201: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2021-11-26 00:11:28.210069: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-11-26 00:11:28.210085: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2021-11-26 00:11:28.306809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "model_lite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f_out:\n",
    "    f_out.write(model_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.787506103515625 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filesize = os.path.getsize('model.tflite')\n",
    "print(f'{ filesize / (1024**2)} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 answer\n",
    "\n",
    "Around `43` MB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and the index of the output.\n",
    "\n",
    "What's the output index for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "print(output_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Answer\n",
    "\n",
    "The output index for the lite model is `13`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the image\n",
    "\n",
    "You'll need some code for downloading and resizing images. You'll need pillow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pillow\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install pillow\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download and resize this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OH GOD WHAT AM I DOING\n",
    "DON'T USE THIS BLOCK YOU IDIOT\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USE THIS BLOCK INSTEAD\n",
    "'''\n",
    "img = prepare_image(\n",
    "    download_image('https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg'),\n",
    "    (150, 150)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [the solution of the previous homework](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/08-deep-learning/CNN_solution.ipynb), what should be the target size for the image?\n",
    "\n",
    "* `150x150`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Now we need to turn the image into an numpy array and pre-process it.\n",
    "\n",
    "> Tip: Check the previous homework. What was the pre-processing we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since we do not have to train the network, we do not need data augmentation.\n",
    "\n",
    "The main pre-processing is image resizing and rescaling, then.\n",
    "\n",
    "target_size=(150,150)\n",
    "rescale=1./255\n",
    "dtype=float32\n",
    "'''\n",
    "\n",
    "'''\n",
    "DON'T USE THIS BLOCK\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "img = load_img('Pug_600.jpg', target_size=(150,150))\n",
    "x = np.array(img, dtype='float32')\n",
    "x = x/ 255\n",
    "\n",
    "x[0,0,0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ALTERNATIVE VERSION\n",
    "No TF dependency\n",
    "\n",
    "DON'T USE THIS BLOCK EITHER\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "with Image.open('Pug_600.jpg') as img:\n",
    "    img = img.resize((150, 150), Image.NEAREST)\n",
    "x = np.array(img, dtype='float32')\n",
    "x = x/ 255\n",
    "\n",
    "x[0,0,0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "USE ME INSTEAD\n",
    "'''\n",
    "\n",
    "x = np.array(img, dtype='float32')\n",
    "x = x/ 255\n",
    "\n",
    "x[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 answer\n",
    "\n",
    "The value of the first pixel is `0.7058824`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchify\n",
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7704913]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 answer\n",
    "\n",
    "The output of the model is `0.7704913`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Lambda code\n",
    "\n",
    "Now you need to copy all the code into a separate python file. You will need to use this file for the next two questions.\n",
    "\n",
    "Tip: you can test this file locally with `ipython` or Jupyter Notebook by importing the file and invoking the function from this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Continued in `homework2.ipynb`)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1db84734a3d3d0c15f6b4b965815f8c27842eefe55dee7e4ba0964aee0f6be8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
